---
layout: post
title:  "RNN Series:LSTMs:Part-1:The Big Picture"
excerpt: "The marriage of Softmax and CrossEntropy. This is a loss calculating function post the yhat(predicted value) that measures the difference between Labels and predicted value(yhat). "
mathjax: true
date:   2019-05-03 15:07:19
categories: [article]
tags: Artificial-Intelligence Deep-learning
comments: true
---

### Introduction
[eq-1]: softmax-and-its-gradient#eq-1
[eq-2]: softmax-and-cross-entropy#eq-2
[loss]: https://github.com/slowbreathing/Deep-Breathe/blob/master/org/mk/training/dl/common.py
[CrossEntropyLoss]: https://github.com/slowbreathing/Deep-Breathe/blob/master/org/mk/training/dl/common.py
[softmaxtest]: https://github.com/slowbreathing/Deep-Breathe/blob/master/org/mk/training/dl/softmaxtest.py
[Deep-Breathe]: https://github.com/slowbreathing/Deep-Breathe
