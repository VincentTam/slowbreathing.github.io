<!DOCTYPE html>
<html lang="en">





<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="description" content="In this multi-part series we look inside LSTM forward pass. Read the part-1's before you come back here. Once you are back, in this article, we explore the m...">
  <meta name="keywords" content="blog and jekyll">
  <meta name="author" content="RNN Series:LSTM internals:Part-2:The Forward pass | Slowbreathing">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#f5f5f5">

  <!-- Twitter Tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="RNN Series:LSTM internals:Part-2:The Forward pass | Slowbreathing">
  <meta name="twitter:description" content="In this multi-part series we look inside LSTM forward pass. Read the part-1&#39;s before you come back here. Once you are back, in this article, we explore the m...">
  
    <meta property="twitter:image" content="http://localhost:4000/img/leonids-logo.png">
  

  <!-- Open Graph Tags -->
  <meta property="og:type" content="blog">
  <meta property="og:url" content="http://localhost:4000/articles/2019-07/LSTMPart-2">
  <meta property="og:title" content="RNN Series:LSTM internals:Part-2:The Forward pass | Slowbreathing">
  <meta property="og:description" content="In this multi-part series we look inside LSTM forward pass. Read the part-1&#39;s before you come back here. Once you are back, in this article, we explore the m...">
  
    <meta property="og:image" content="http://localhost:4000/img/leonids-logo.png">
  
  <title>RNN Series:LSTM internals:Part-2:The Forward pass | Slowbreathing</title>

  <!-- CSS files -->
  <link rel="stylesheet" href="http://localhost:4000/css/font-awesome.min.css">
  <link rel="stylesheet" href="http://localhost:4000/css/main.css">

  <link rel="canonical" href="http://localhost:4000/articles/2019-07/LSTMPart-2">
  <link rel="alternate" type="application/rss+xml" title="Slowbreathing" href="http://localhost:4000/feed.xml" />

  <!-- Icons -->
  <!-- 16x16 -->
  <link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
  <!-- 32x32 -->
  <link rel="shortcut icon" href="http://localhost:4000/favicon.png">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!--<script async src="https://www.googletagmanager.com/gtag/js?id=UA-142206738-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-142206738-1');
  </script>-->

</head>


<body>
  <div class="row">
    <div class="col s12 m3">
      <div class="table cover">
        

<div class="cover-card table-cell table-middle">
  
  <a href="http://localhost:4000/">
    <img src="http://localhost:4000/img/leonids-logo.png" alt="" class="avatar">
  </a>
  
  <a href="http://localhost:4000/" class="author_name">Mohit Kumar</a>
  <span class="author_job">Researcher/Consultant/Trainer</span>
  <span class="author_bio mbm">Programming is more than just typing.</span>
  <nav class="nav">
    <ul class="nav-list">
      <li class="nav-item">
        <a href="http://localhost:4000/">home</a>
      </li>
       
      <li class="nav-item">
        <a href="http://localhost:4000/archive/">Archive</a>
      </li>
          
      <li class="nav-item">
        <a href="http://localhost:4000/categories/">Categories</a>
      </li>
            
      <li class="nav-item">
        <a href="http://localhost:4000/resume/">about me</a>
      </li>
        
      <li class="nav-item">
        <a href="http://localhost:4000/tags/">Tags</a>
      </li>
         
    </ul>
  </nav>
  <script type="text/javascript">
  // based on https://stackoverflow.com/a/10300743/280842
  function gen_mail_to_link(hs, subject) {
    var lhs,rhs;
    var p = hs.split('@');
    lhs = p[0];
    rhs = p[1];
    document.write("<a class=\"social-link-item\" target=\"_blank\" href=\"mailto");
    document.write(":" + lhs + "@");
    document.write(rhs + "?subject=" + subject + "\"><i class=\"fa fa-fw fa-envelope\"></i><\/a>");
  }
</script>
<div class="social-links">
  <ul>
    
      <li>
      <script>gen_mail_to_link('mohit.riverstone@gmail.com', 'Hello from website');</script>
      </li>
    
    
    <li><a href="https://facebook.com/mohit.kumar.965" class="social-link-item" target="_blank"><i class="fa fa-fw fa-facebook"></i></a></li>
    
    <li><a href="https://linkedin.com/in/mohit-kumar-36050a65" class="social-link-item" target="_blank"><i class="fa fa-fw fa-linkedin"></i></a></li>
    
    
    
    
    <li><a href="https://github.com/Slowbreathing" class="social-link-item" target="_blank"><i class="fa fa-fw fa-github"></i></a></li>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
  </ul>
</div>

</div>

      </div>
    </div>
    <div class="col s12 m9">
      <div class="post-listing">
        <a class="btn" href= "http://localhost:4000/" >
  Home
</a>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
>
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://vincenttam.github.io/javascripts/MathJaxLocal.js"
>
</script>





<div id="post">
  <header class="post-header">
    <h1 title="RNN Series:LSTM internals:Part-2:The Forward pass">RNN Series:LSTM internals:Part-2:The Forward pass</h1>
    <span class="post-meta">
      <span class="post-date">
        9 JUL 2019
      </span>
      •
      <span class="read-time" title="Estimated read time">
  
  
    12 mins read
  
</span>

    </span>

  </header>

  <article class="post-content">
    <h3 id="introduction">Introduction</h3>
<p><strong>In this multi-part series we look inside LSTM forward pass.</strong> Read the <a href="/articles/2019-07/LSTMPart-1">part-1’s</a> before you come back here. Once you are back, in this article, we explore the meaning, math and the implementation of an LSTM cell. <strong>I do this using the first principles approach for which I have pure python implementation Deep-Breathe of most complex Deep Learning models.</strong></p>

<h3 id="what-this-article-is-not-about">What this article is not about?</h3>
<blockquote>
  <ul>
    <li>This article will not talk about the conceptual model of LSTM, on which there are some great existing material [here][lstm-1] and <a href="https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html">here</a> in thye order of difficulty.</li>
    <li>This is not about the differences between vanilla RNN and LSTMs, on which there is an awesome post by Andrej if somewhat <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">difficult post</a>.</li>
    <li>This is not about how LSTMs mitigate the vanishing gradient problem, on which there is a little mathy but awesome posts <a href="https://weberna.github.io/blog/2017/11/15/LSTM-Vanishing-Gradients.html">here</a> and <a href="https://medium.com/datadriveninvestor/how-do-lstm-networks-solve-the-problem-of-vanishing-gradients-a6784971a577">here</a> in the order of difficulty</li>
  </ul>
</blockquote>

<h3 id="what-this-article-is-about">What this article is about?</h3>
<blockquote>
  <ul>
    <li>Using the <a href="https://medium.com/the-mission/elon-musks-3-step-first-principles-thinking-how-to-think-and-solve-difficult-problems-like-a-ba1e73a9f6c0">first principles</a> we picturize the forward pass of an LSTM cell.</li>
    <li>Then we associate code with picture to make our understanding more concrete</li>
  </ul>
</blockquote>

<h3 id="context">Context</h3>
<p>This is the same example and the context is the same as described in <a href="/articles/2019-07/LSTMPart-1">part-1</a>. <strong>The focus however, this time is on LSTM cell.</strong></p>

<h3 id="lstm-cell">LSTM Cell</h3>
<p>While there are many variations to the LSTM cell. In the current article we are looking at <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LayerNormBasicLSTMCell">LayerNormBasicLSTMCell</a>.</p>
<blockquote>
  <ul>
    <li>Weights and biases of the LSTM cell.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm1.jpg" alt="Image: figure-1: Batch=1, State=5(internal states(C and H)), input_size=10(assuming vocab size of 10 translates to one-hot of size 10) ." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-1: Batch=1, State=5(internal states(C and H)), input_size=10(assuming vocab size of 10 translates to one-hot of size 10) .</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Weights, biases of the LSTM cell. Also shown is the cell state (c-state) over and above the h-state of a vanilla RNN.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm2.jpg" alt="Image: figure-2: Weights and biases for all the gates f(forget), i(input), c(candidatecellstate), o(output). Shape of these &lt;strong&gt;weights&lt;/strong&gt; are &lt;strong&gt;5X15&lt;/strong&gt; individually and stacked vertically as shown they measure &lt;strong&gt;20X15&lt;/strong&gt;. Shape of the &lt;strong&gt;biases&lt;/strong&gt; are &lt;strong&gt;5X1&lt;/strong&gt; individually and stacked up &lt;strong&gt;20X1&lt;/strong&gt;." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-2: Weights and biases for all the gates f(forget), i(input), c(candidatecellstate), o(output). Shape of these <strong>weights</strong> are <strong>5X15</strong> individually and stacked vertically as shown they measure <strong>20X15</strong>. Shape of the <strong>biases</strong> are <strong>5X1</strong> individually and stacked up <strong>20X1</strong>.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Weights and biases in the <a href="https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/org/mk/training/dl/rnn_cell.py#L76">code</a>.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm3.jpg" alt="Image: figure-3: &lt;strong&gt;4*hidden_size(5),input_size(10)+hidden_size(5)+1(biases)&lt;/strong&gt;. Making it &lt;strong&gt;20X16&lt;/strong&gt;, biases allocated with weights is a matter of convenience and performance." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-3: <strong>4*hidden_size(5),input_size(10)+hidden_size(5)+1(biases)</strong>. Making it <strong>20X16</strong>, biases allocated with weights is a matter of convenience and performance.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Equations of LSTM and their interplay with weights and biases.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm4.jpg" alt="Image: figure-4: Equations of LSTM and their interplay with weights and biases." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-4: Equations of LSTM and their interplay with weights and biases.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>GEMM(General Matrix Multiplication) in <a href="https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/org/mk/training/dl/rnn_cell.py#L210-L214">code</a></li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm5.jpg" alt="Image: figure-5: GEMM and running them though various gates." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-5: GEMM and running them though various gates.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>The <strong>mathematical reason</strong> why <strong>vanishing gradient</strong> is <strong>mitigated</strong>.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm6.jpg" alt="Image: figure-2: New cell state is a function of old cell state and new candidate state." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-2: New cell state is a function of old cell state and new candidate state.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Sequence of 3 shown below, but that can depend on the use-case.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm7.jpg" alt="Image: figure-2: Batch enables parallelism, but for simplicity assumed as one." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-2: Batch enables parallelism, but for simplicity assumed as one.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Sequence of 3 shown below, but that can depend on the use-case.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm8.jpg" alt="Image: figure-2: Batch enables parallelism, but for simplicity assumed as one." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-2: Batch enables parallelism, but for simplicity assumed as one.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Sequence of 3 shown below, but that can depend on the use-case.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm9.jpg" alt="Image: figure-2: Batch enables parallelism, but for simplicity assumed as one." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-2: Batch enables parallelism, but for simplicity assumed as one.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Sequence of 3 shown below, but that can depend on the use-case.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm10.jpg" alt="Image: figure-2: Batch enables parallelism, but for simplicity assumed as one." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-2: Batch enables parallelism, but for simplicity assumed as one.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Sequence of 3 shown below, but that can depend on the use-case.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm11.jpg" alt="Image: figure-2: Batch enables parallelism, but for simplicity assumed as one." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-2: Batch enables parallelism, but for simplicity assumed as one.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Sequence of 3 shown below, but that can depend on the use-case.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm12.jpg" alt="Image: figure-2: Batch enables parallelism, but for simplicity assumed as one." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-2: Batch enables parallelism, but for simplicity assumed as one.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Sequence of 3 shown below, but that can depend on the use-case.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm13.jpg" alt="Image: figure-2: Batch enables parallelism, but for simplicity assumed as one." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-2: Batch enables parallelism, but for simplicity assumed as one.</span></center></figcaption>
</figure>

<blockquote>
  <ul>
    <li>Sequence of 3 shown below, but that can depend on the use-case.</li>
  </ul>
</blockquote>

<figure>
    
    <img src="/img/rnn/lstm14.jpg" alt="Image: figure-2: Batch enables parallelism, but for simplicity assumed as one." hight="110%" width="110%" />
    
    <figcaption><center><span class="faded_text">figure-2: Batch enables parallelism, but for simplicity assumed as one.</span></center></figcaption>
</figure>

<h3 id="quick-comparision-between-tensorflow-and-deep-breathe">Quick Comparision between <a href="https://www.tensorflow.org/">Tensorflow</a> and <a href="https://github.com/slowbreathing/Deep-Breathe">DEEP-Breathe</a></h3>

<p>This particular branch of <a href="https://github.com/slowbreathing/Deep-Breathe">DEEP-Breathe</a> has been designed to compare weights with <a href="https://www.tensorflow.org/">Tensorflow</a> code every step of the way. While there are many reasons, one of the primary reasons for that is understanding. However, this is only possible if both <a href="https://www.tensorflow.org/">Tensorflow</a> and <a href="https://github.com/slowbreathing/Deep-Breathe">DEEP-Breathe</a> must start with the same initial weights and their Y-multipliers(Wy and By) must also be identical. Consider the code below.</p>

<h4 id="tensorflow"><a href="https://www.tensorflow.org/">Tensorflow</a></h4>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
</pre></td><td class="code"><pre>  <span class="c"># RNN output node weights and biases</span>
  <span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'out'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.09588283</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.2044923</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.74828255</span><span class="p">,</span>  <span class="mf">0.14180686</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.32083616</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">0.9444244</span> <span class="p">,</span>  <span class="mf">0.06826905</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9728962</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.18506959</span><span class="p">,</span>  <span class="mf">1.0618515</span> <span class="p">],</span>
       <span class="p">[</span> <span class="mf">1.156649</span>  <span class="p">,</span>  <span class="mf">3.2738173</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.2556943</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.9079511</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.82127047</span><span class="p">,</span>
        <span class="o">-</span><span class="mf">1.1448543</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.60807484</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5885713</span> <span class="p">,</span>  <span class="mf">1.0378786</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.7088431</span> <span class="p">],</span>
       <span class="p">[</span> <span class="mf">1.006477</span>  <span class="p">,</span>  <span class="mf">0.28033388</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1804534</span> <span class="p">,</span>  <span class="mf">0.8093307</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.36991575</span><span class="p">,</span>
         <span class="mf">0.29115433</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01028167</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7357091</span> <span class="p">,</span>  <span class="mf">0.92254084</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.10753923</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.19266959</span><span class="p">,</span>  <span class="mf">0.6108299</span> <span class="p">,</span>  <span class="mf">2.2495654</span> <span class="p">,</span>  <span class="mf">1.5288974</span> <span class="p">,</span>  <span class="mf">1.0172302</span> <span class="p">,</span>
         <span class="mf">1.1311738</span> <span class="p">,</span>  <span class="mf">0.2666629</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.30611828</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01412263</span><span class="p">,</span>  <span class="mf">0.44799015</span><span class="p">],</span>
       <span class="p">[</span> <span class="mf">0.19266959</span><span class="p">,</span>  <span class="mf">0.6108299</span> <span class="p">,</span>  <span class="mf">2.2495654</span> <span class="p">,</span>  <span class="mf">1.5288974</span> <span class="p">,</span>  <span class="mf">1.0172302</span> <span class="p">,</span>
         <span class="mf">1.1311738</span> <span class="p">,</span>  <span class="mf">0.2666629</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.30611828</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01412263</span><span class="p">,</span>  <span class="mf">0.44799015</span><span class="p">]]</span>

        <span class="p">)</span>
  <span class="p">}</span>
  <span class="n">biases</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'out'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">([</span> <span class="mf">0.1458478</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.3660951</span> <span class="p">,</span> <span class="o">-</span><span class="mf">2.1647317</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.9633691</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.24532059</span><span class="p">,</span>
        <span class="mf">0.14005205</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0961286</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.43737876</span><span class="p">,</span>  <span class="mf">0.7028531</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.8481724</span> <span class="p">]</span>
    <span class="p">)</span>
  <span class="p">}</span>
  <span class="k">def</span> <span class="nf">RNN</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">biases</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">variable_scope</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span>
            <span class="s">"other"</span><span class="p">,</span> <span class="n">initializer</span><span class="o">=</span><span class="n">init_ops</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span> <span class="k">as</span> <span class="n">vs</span><span class="p">:</span>
        <span class="n">cell</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LayerNormBasicLSTMCell</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">layer_norm</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="s">'out'</span><span class="p">])[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">biases</span><span class="p">[</span><span class="s">'out'</span><span class="p">],</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">states</span><span class="p">,</span><span class="n">weights</span><span class="p">[</span><span class="s">'out'</span><span class="p">],</span><span class="n">biases</span><span class="p">[</span><span class="s">'out'</span><span class="p">]</span>
  <span class="n">pred</span><span class="p">,</span><span class="n">output</span><span class="p">,</span><span class="n">state</span><span class="p">,</span><span class="n">weights_out</span><span class="p">,</span><span class="n">biases_out</span> <span class="o">=</span> <span class="n">RNN</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">biases</span><span class="p">)</span>

<span class="n">Listing</span><span class="o">-</span><span class="mi">1</span></pre></td></tr></tbody></table></code></pre></figure>

<blockquote>
  <ul>
    <li>The pre-initialized weights and biases in line(2) and line(16) utilized as Wy and By in line(26)</li>
    <li>The internal weights of LSTM initialized in line(22-23)</li>
    <li><strong>Tensorflow graph mode is the most non pythonic design done in python</strong>. It sounds crazy but is true. Consider line(21-26), this function gets called multiple times in the training loop and yet the <strong>cell(line(24)) is the same cell instance across multiple iterations</strong>. Tensorflow in the graph mode builds the DAG first and <strong>identifies the cell by the name in that graph</strong>. That is source of confusion to most programmers, especially python programmers.</li>
    <li>The complete executable <a href="https://github.com/slowbreathing/Deep-Breathe/blob/master/org/mk/training/dl/tfwordslstm.py">Listing-1</a> and its <a href="https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/scripts#L13">execution script</a>.</li>
  </ul>
</blockquote>

<h4 id="deep-breathe"><a href="https://github.com/slowbreathing/Deep-Breathe">Deep-Breathe</a></h4>

<p>I could have done without a similar behaviour in <a href="https://github.com/slowbreathing/Deep-Breathe">Deep-Breathe</a> but the programmer in me just could not resist. Especially since I earned my stripes in C/C++ and assembly kind of languages, python proved challenging. <strong>Without building a full fleged graph, I associated the variable name with the corresonding weight, i.e. when the variable name is same it fetches the same set of weights </strong>. This is difficult and not reccomended but, if you care to see, then its demonstrated <a href="https://github.com/slowbreathing/Deep-Breathe/blob/c3b538d9c3afeeb5a15c3d91ea9063976438c810/org/mk/training/dl/rnn.py#L75-L76">here</a>,<a href="https://github.com/slowbreathing/Deep-Breathe/blob/c3b538d9c3afeeb5a15c3d91ea9063976438c810/org/mk/training/dl/common.py#L241-L255">here</a>,<a href="https://github.com/slowbreathing/Deep-Breathe/blob/c3b538d9c3afeeb5a15c3d91ea9063976438c810/org/mk/training/dl/rnn_cell.py#L79-L81">here</a> and <a href="https://github.com/slowbreathing/Deep-Breathe/blob/c3b538d9c3afeeb5a15c3d91ea9063976438c810/org/mk/training/dl/core.py#L107-L112">here</a>. <strong>To summarize in the Listing-2 there is a single set of weights for the LSTMCell despite getting called multiple times in the loop.</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td class="code"><pre><span class="k">def</span> <span class="nf">RNN</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">biases</span><span class="p">):</span>
  <span class="k">with</span> <span class="n">WeightsInitializer</span><span class="p">(</span><span class="n">initializer</span><span class="o">=</span><span class="n">init_ops</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span> <span class="k">as</span> <span class="n">vs</span><span class="p">:</span>
      <span class="n">cell</span> <span class="o">=</span> <span class="n">LSTMCell</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span><span class="n">debug</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="n">result</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">symbols_in_keys</span><span class="p">)</span>
  <span class="s">"Dense in this case should be out of WeightsInitializer scope because we are passing constants"</span>
  <span class="n">out_l</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="n">kernel_initializer</span><span class="o">=</span><span class="n">init_ops</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">out_weights</span><span class="p">),</span><span class="n">bias_initializer</span><span class="o">=</span><span class="n">init_ops</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">out_biases</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">out_l</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">h</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">LOSS</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">target</span><span class="p">):</span>
  <span class="n">pred</span><span class="o">=</span><span class="n">RNN</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">out_weights</span><span class="p">,</span><span class="n">out_biases</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">cross_entropy_loss</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">vocab_size</span><span class="p">]),</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">target</span><span class="p">]]))</span>

<span class="k">while</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="n">training_iters</span><span class="p">:</span>
  <span class="k">if</span> <span class="n">offset</span> <span class="o">&gt;</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">-</span> <span class="n">end_offset</span><span class="p">):</span>
      <span class="n">offset</span> <span class="o">=</span> <span class="n">rnd</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_input</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"offset:"</span><span class="p">,</span> <span class="n">offset</span><span class="p">)</span>
  <span class="n">symbols_in_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_one_hot</span><span class="p">(</span><span class="n">dictionary</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="n">i</span><span class="p">])],</span><span class="n">vocab_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">n_input</span><span class="p">)]</span>
  <span class="n">symbols_in_keys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">symbols_in_keys</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_input</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">])</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"symbols_in_keys:"</span><span class="p">,</span><span class="n">symbols_in_keys</span><span class="p">)</span>
  <span class="n">target</span><span class="o">=</span><span class="n">dictionary</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="n">offset</span> <span class="o">+</span> <span class="n">n_input</span><span class="p">])]</span>
  <span class="n">yhat</span><span class="p">,</span><span class="n">cel</span><span class="o">=</span><span class="n">LOSS</span><span class="p">(</span><span class="n">symbols_in_keys</span><span class="p">,</span><span class="n">target</span><span class="p">)</span>


<span class="n">Listing</span><span class="o">-</span><span class="mi">2</span></pre></td></tr></tbody></table></code></pre></figure>

<blockquote>
  <ul>
    <li>The complete executable <a href="https://github.com/slowbreathing/Deep-Breathe/blob/master/org/mk/training/dl/LSTMMainGraph.py">graph-mode</a> and its <a href="https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/scripts#L15">execution script</a>.</li>
    <li>The complete executable for <a href="https://github.com/slowbreathing/Deep-Breathe/blob/master/org/mk/training/dl/LSTMMain.py">non-graph-version</a> and its <a href="https://github.com/slowbreathing/Deep-Breathe/blob/f9585bde9cbb61e71f67ccd936aa22a155c36709/scripts#L14">execution script</a>. To make Tensorflow more pythonic, they have enabled eager mode and will be the default going forward especially from Tensorflow 2.0 onwards. However, major project as on today is still on the older version.</li>
  </ul>
</blockquote>

<h3 id="summary">Summary</h3>
<p>In summary then, that was the walk though of code surrounding LSTM training, without getting into LSTM or its weights just yet. That would be the topic of our next article.</p>


  </article>
</div>

<div class="share-buttons">
  <h6>Share on: </h6>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/articles/2019-07/LSTMPart-2" class="twitter btn" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/articles/2019-07/LSTMPart-2" class="facebook btn" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=http://localhost:4000/articles/2019-07/LSTMPart-2" class="google-plus btn" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
    <li>
      <a href="https://news.ycombinator.com/submitlink?u=http://localhost:4000/articles/2019-07/LSTMPart-2" class="hacker-news btn" title="Share on Hacker News"><i class="fa fa-hacker-news"></i><span> Hacker News</span></a>
    </li>
    <li>
      <a href="https://www.reddit.com/submit?url=http://localhost:4000/articles/2019-07/LSTMPart-2" class="reddit btn" title="Share on Reddit"><i class="fa fa-reddit"></i><span> Reddit</span></a>
    </li>
  </ul>
</div><!-- end share-buttons -->



        <footer>
  <strong>MIT License</strong> &copy; 2019 Mohit Kumar.
</footer>

      </div>
    </div>
  </div>
  <script type="text/javascript" src="http://localhost:4000/js/jquery-3.2.1.min.js"></script>
<script type="text/javascript" src="http://localhost:4000/js/main.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-142206738-1', 'auto');
  ga('send', 'pageview');
</script>



</body>
</html>
